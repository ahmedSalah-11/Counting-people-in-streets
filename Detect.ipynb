{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo(object) :\n",
    "    def __init__(self,weights_path, cfg_path, coco_path) :\n",
    "        self.net= cv2.dnn.readNet(weights_path, cfg_path)\n",
    "        self.regions=[\n",
    "                    [27,129,230,289] ,\n",
    "                    [287,156,711,431],\n",
    "                    [10,8,755,566],   \n",
    "                    ]\n",
    "        self.out = None \n",
    "        self.cap = None\n",
    "        self.classes=self.setClasses(coco_path)\n",
    "        \n",
    "    def checkRegion(self, x_center, y_center) :\n",
    "        \"\"\"\n",
    "        returns the region that the bbox belongs to (0 if none)\n",
    "        \"\"\"\n",
    "        for i,region in enumerate(self.regions) :\n",
    "            if region[0] <= x_center <=region[2] and region[1]<=y_center<=region[3] :\n",
    "                    return i+1\n",
    "        return 0\n",
    "    \n",
    "    def drawRegions(self,image):\n",
    "        colors=[(0, 0, 255),(0, 255, 0),(255, 0, 0)]\n",
    "        for i,region in enumerate(self.regions):\n",
    "            cv2.rectangle(image, (region[0],region[1]), (region[2],region[3]), colors[i], 2)\n",
    "    \n",
    "    def drawCounts(self,regions_count,image) :\n",
    "        #Region-3 count(smallest)\n",
    "        cv2.putText(image, 'Count = '+str(regions_count[1]), (100,280), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "        #Region-2 count(mid)\n",
    "        cv2.putText(image, 'Count = '+str(regions_count[2]), (450,410), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255, 0), 2)\n",
    "        #Region-1 count(largest)\n",
    "        cv2.putText(image, 'Count = '+str(regions_count[1]+regions_count[2]+regions_count[3]), (400,40), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 0, 0), 2)\n",
    "        \n",
    "    def setClasses(self,path) :\n",
    "        \"\"\"\n",
    "        return  classes names that yolo can detect\n",
    "        \"\"\"\n",
    "        with open(path, 'r') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "        return classes\n",
    "    \n",
    "    def detect(self,imagesPath,outputPath) :\n",
    "        self.cap=cv2.VideoCapture(imagesPath)\n",
    "        self.out=cv2.VideoWriter(outputPath + 'output.mp4',cv2.VideoWriter_fourcc('m','p','4','v'), 6, (768,576))\n",
    "        \n",
    "        while 1 :\n",
    "            ret, image = self.cap.read()\n",
    "            if ret:\n",
    "                self.net.setInput(cv2.dnn.blobFromImage(image, 0.00392, (416,416), (0,0,0), True, crop=False))\n",
    "                layer_names = self.net.getLayerNames()\n",
    "                output_layers = [layer_names[i[0] - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "                outs = self.net.forward(output_layers)\n",
    "                \n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "                boxes_centers=[]\n",
    "                Width = image.shape[1]\n",
    "                Height = image.shape[0]\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.5:\n",
    "                            center_x = int(detection[0] * Width)\n",
    "                            center_y = int(detection[1] * Height)\n",
    "                            \n",
    "                            w = int(detection[2] * Width)\n",
    "                            h = int(detection[3] * Height)\n",
    "                            \n",
    "                            x = center_x - w / 2\n",
    "                            y = center_y - h / 2\n",
    "                            \n",
    "                            class_ids.append(class_id)\n",
    "                            confidences.append(float(confidence))\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            boxes_centers.append([center_x,center_y])\n",
    "\n",
    "                indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.1)\n",
    "                regions_count=collections.defaultdict(int)\n",
    "                for i in indices:\n",
    "                    i = i[0]\n",
    "                    box = boxes[i]\n",
    "                    #check if person detection\n",
    "                    if class_ids[i]==0:\n",
    "                            region= self.checkRegion(*boxes_centers[i])\n",
    "                            if region :\n",
    "                                label = str(self.classes[class_id]) \n",
    "                                cv2.rectangle(image, (round(box[0]),round(box[1])), (round(box[0]+box[2]),round(box[1]+box[3])), (0, 0, 0), 2)\n",
    "                                cv2.putText(image, label, (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "                                regions_count[region]+=1\n",
    "                self.drawRegions(image)\n",
    "                self.drawCounts(regions_count,image)\n",
    "                cv2.imshow('frame',image)\n",
    "                self.out.write(image)\n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                        break\n",
    "                        \n",
    "            else : \n",
    "                break\n",
    "                \n",
    "        self.cap.release() \n",
    "        self.out.release()\n",
    "        cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating output directories and input data paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths=[]\n",
    "for i in range(1,5) :\n",
    "    path1= \"./S1_L1/Crowd_PETS09/S1/L1/Time_13-57/View_00{}/frame_%04d.jpg\".format(i)\n",
    "    path2='./S1_L1/Crowd_PETS09/S1/L1/Time_13-59/View_00{}/frame_%04d.jpg'.format(i)\n",
    "    input_paths.extend([path1,path2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_paths=[]\n",
    "for i in range(1,5) :\n",
    "    path1=\"S1_L1_output/Crowd_PETS09/S1/L1/Time_13-57_output/View_00{}_output/\".format(i)\n",
    "    path2=\"S1_L1_output/Crowd_PETS09/S1/L1/Time_13-59_output/View_00{}_output/\".format(i)\n",
    "    output_paths.extend([path1,path2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in output_paths :\n",
    "    try :\n",
    "        os.makedirs(path)\n",
    "    except :\n",
    "        print(path+' is already created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intializing and running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path='./Yolo_files/yolov3.weights'\n",
    "cfg_path='./Yolo_files/yolov3.cfg'\n",
    "names_path='./Yolo_files/coco.names'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo=Yolo(weights_path, cfg_path, names_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each input frame from input_path and saves it's output in output_path \n",
    "for input_path,output_path in zip (input_paths,output_paths) :\n",
    "    yolo.detect(input_path,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
